{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necesary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akils\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the CSV file\n",
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "\n",
    "#Check for duplicates in dataframe\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "#Downloading stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes punctuation from words as well as stopwords\n",
    "\n",
    "def process_text(text):\n",
    "    #1 Remoe punctuation\n",
    "    #2 Remove stopwords(useless words)\n",
    "    #3 return a list of clean text words\n",
    "\n",
    "    #1 \n",
    "\n",
    "    #List compression, where loops through each charecter to see if its a punctuation. This is still \n",
    "    #a string. \n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "\n",
    "    #Attaches a space at beggining of nopunc\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    #2 \n",
    "\n",
    "    #Loops through every word in nopunc(split seperates text )\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the vectorization layer, processes training data text, and adapts it to model\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens = 45000, output_mode = \"count\", pad_to_max_tokens=45000)\n",
    "pre_processed_text = process_text(df['text'])\n",
    "vectorize_layer.adapt(pre_processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633    Subject: phillips petroleum\\r\\ni wanted to upd...\n",
      "3045    Subject: hpl meter # 986290 indian hills plant...\n",
      "354     Subject: submision result\\r\\nhave you heard ?\\...\n",
      "4269    Subject: shelby why can ' t you call me back ?...\n",
      "3965    Subject: new nomination\\r\\n- - - - - - - - - -...\n",
      "                              ...                        \n",
      "1579    Subject: we have vicodin and anything else\\r\\n...\n",
      "1962    Subject: mobil february , 2000 activity\\r\\ndo ...\n",
      "5080    Subject: hpl nom for august 17 , 2000\\r\\n( see...\n",
      "2238    Subject: hpl nom for april 21 - 23 , 2001\\r\\n(...\n",
      "557     Subject: re : inquiry ?\\r\\nbecky ,\\r\\ncan we g...\n",
      "Name: text, Length: 3464, dtype: object\n",
      "1633    0\n",
      "3045    0\n",
      "354     1\n",
      "4269    1\n",
      "3965    0\n",
      "       ..\n",
      "1579    1\n",
      "1962    0\n",
      "5080    0\n",
      "2238    0\n",
      "557     0\n",
      "Name: label_num, Length: 3464, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Defines training and testing data, splitting 67:33\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label_num'], test_size = 0.33)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "lambda_values = np.asarray([0, 0.001, 0.002, 0.004, 0.008, 0.01, 0.02, 0.04, 0.08, 0.1, 0.2, 0.4])\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building of model: takes in a string input, converts it to a vector, and makes it go through four layers\n",
    "\n",
    "def create_new_model(lambdaValue):\n",
    "    model =  tf.keras.models.Sequential(\n",
    "        [\n",
    "        tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "        vectorize_layer,\n",
    "        Dense(units = 25, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambdaValue)),\n",
    "        Dense(units = 15, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambdaValue)),\n",
    "        Dense(units = 10, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambdaValue)),\n",
    "        Dense(units = 1, activation = 'sigmoid') \n",
    "\n",
    "    ]\n",
    "    ) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 10ms/step - loss: 0.2481\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0430\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0081\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0049\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0032\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0022\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0015\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0010\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 1s 11ms/step - loss: 0.0073\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0372\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 10ms/step - loss: 0.0013\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 7.7963e-04\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 6.4107e-04\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 5.4523e-04\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.6957e-04\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.0741e-04\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 3.5787e-04\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 3.1442e-04\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 2.7739e-04\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 2.4581e-04\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 2.1890e-04\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.9693e-04\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 1.7783e-04\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 1.6023e-04\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.4381e-04\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.2917e-04\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.1724e-04\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 1.0678e-04\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 9.8039e-05\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 8.9851e-05\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 8.2106e-05\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 7.5681e-05\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 6.9685e-05\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 6.4119e-05\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 5.9179e-05\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 5.4712e-05\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 5.0654e-05\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.7051e-05\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 4.3535e-05\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.3930\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1460\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1169\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0834\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0693\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0627\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0554\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0512\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0516\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0446\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0440\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1065\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1400\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0954\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0784\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0693\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0631\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0558\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0525\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0480\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0437\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0415\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0403\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0381\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.0363\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0359\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1193\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.1013\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0844\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0693\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0591\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0521\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0463\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0427\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0395\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0371\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0363\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0334\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0323\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0315\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.3796\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1452\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1150\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0913\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0731\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0634\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0906\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1471\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1101\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0854\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0704\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0619\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0568\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0526\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0494\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0481\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1078\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1756\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1142\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0859\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0705\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0616\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0547\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0504\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0471\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.0469\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1216\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.0784\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0607\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0529\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0478\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0453\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0425\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.0469\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1071\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0888\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0715\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0669\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0539\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0470\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.4420\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.2186\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1660\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1381\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1415\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1872\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1744\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1328\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1130\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1087\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1197\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.3098\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1572\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1172\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1023\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0940\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0894\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0889\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0856\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0848\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0832\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0874\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2245\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1295\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0946\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.0869\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.0782\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.0973\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1708\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1713\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1241\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0917\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0793\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0865\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1151\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0985\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0793\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0695\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.0673\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.0640\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.6041\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3190\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2515\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2178\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2011\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1938\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.1903\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1711\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1805\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.1597\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1483\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.2125\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 21ms/step - loss: 0.1904\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1419\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1343\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1433\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1272\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.1332\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.1898\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.1877\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.1611\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.1268\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.1228\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.1951\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.1619\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.1234\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.1688\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.1355\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1132\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.1039\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 21ms/step - loss: 0.1028\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1573\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.2216\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.1448\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.1215\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.1033\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.0973\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0924\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 21ms/step - loss: 0.0907\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0877\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.7566\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4396\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.3258\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.2663\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.2515\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 21ms/step - loss: 0.2405\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.2114\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.2537\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.2226\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 20ms/step - loss: 0.2138\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1872\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1795\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.2415\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1888\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1670\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.2074\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1812\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1568\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 19ms/step - loss: 0.1787\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.1492\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1486\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1697\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1520\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.1358\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.1381\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.2768\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2161\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1470\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1313\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1294\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1208\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1333\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1459\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1245\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1182\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1318\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.1241\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1149\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.1148\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1603\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 0.9896\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5942\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4707\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4056\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3815\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.3450\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.3146\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3606\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3262\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3188\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2757\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3111\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3339\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2756\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2574\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2607\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2469\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2453\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2448\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2642\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2419\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2289\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2272\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3433\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2620\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2176\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2143\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2157\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2132\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2241\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2066\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.1953\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.2521\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2228\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1962\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2481\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2347\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2085\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2329\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.1841\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 1.4289\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.8138\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5910\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5032\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4340\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4474\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3914\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3729\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3584\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3687\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3967\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3466\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.3506\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3169\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3682\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3199\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3122\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3688\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3097\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2840\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2800\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2744\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.2818\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2644\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.2885\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2661\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.3153\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2835\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.2570\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2412\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2732\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2504\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2435\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.2610\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2348\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2909\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2325\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.2221\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2262\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.2162\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 2.4522\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 1.3116\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.8648\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.6662\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.5658\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.5288\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5023\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5022\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4873\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4674\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4707\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4797\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4564\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4308\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.4480\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.4754\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.4048\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.4198\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4113\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4077\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3982\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3842\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4251\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3801\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3803\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3771\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.3689\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3629\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3811\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.3651\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3769\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.3566\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.3445\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3430\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.3365\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3764\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3800\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.3300\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3239\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3283\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 3.1209\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 1.6475\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 1.0644\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.8129\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6929\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6360\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6133\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6016\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5814\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5711\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5618\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.5846\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5424\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5468\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.5106\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5218\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.5105\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4963\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4985\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.4759\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4933\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4752\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.4756\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4747\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4623\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.4605\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4320\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.4432\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4781\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4341\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4215\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4120\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.4126\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.4263\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3974\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3998\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3949\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3942\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3916\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.3898\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 5.2350\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 2.4330\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 1.3816\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.9277\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.7421\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6644\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6339\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6209\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6146\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6095\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6046\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6021\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6017\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6015\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6018\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6014\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6013\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6012\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 1s 14ms/step - loss: 0.6013\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.6014\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6011\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6013\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.6013\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6012\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6014\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6015\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6014\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 1/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 9.7751\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 4.2415\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 2.1257\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 1.2085\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.8247\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.6780\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6258\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.6088\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6036\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6019\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6015\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.6014\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6013\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 2s 16ms/step - loss: 0.6012\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.6012\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6016\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6012\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6011\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6011\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 2s 17ms/step - loss: 0.6013\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 2s 18ms/step - loss: 0.6012\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6013\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6011\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 27/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 28/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 29/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6013\n",
      "Epoch 30/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6011\n",
      "Epoch 31/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6013\n",
      "Epoch 32/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 33/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6012\n",
      "Epoch 34/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6012\n",
      "Epoch 35/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n",
      "Epoch 36/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6011\n",
      "Epoch 37/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6012\n",
      "Epoch 38/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6011\n",
      "Epoch 39/40\n",
      "109/109 [==============================] - 2s 14ms/step - loss: 0.6011\n",
      "Epoch 40/40\n",
      "109/109 [==============================] - 2s 15ms/step - loss: 0.6012\n"
     ]
    }
   ],
   "source": [
    "# Compiles and fits the model\n",
    "\n",
    "for i in range(len(lambda_values)):\n",
    "    models.append(create_new_model(lambda_values[i]))\n",
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=40\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "109/109 [==============================] - 1s 6ms/step\n",
      "54/54 [==============================] - 0s 7ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 6ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 5ms/step\n",
      "54/54 [==============================] - 0s 5ms/step\n",
      "109/109 [==============================] - 1s 6ms/step\n",
      "54/54 [==============================] - 0s 6ms/step\n",
      "(0.0, 0.9853544229642648, 1.0, 0.9778225806451613, 0.9719438877755511)\n",
      "\n",
      "\n",
      "(0.001, 0.9830111306385472, 1.0, 0.9644268774703557, 0.9779559118236473)\n",
      "\n",
      "\n",
      "(0.002, 0.9830111306385472, 1.0, 0.9662698412698413, 0.9759519038076152)\n",
      "\n",
      "\n",
      "(0.004, 0.9794961921499707, 0.9988452655889145, 0.9734693877551021, 0.9559118236472945)\n",
      "\n",
      "\n",
      "(0.008, 0.9824253075571178, 0.9997113163972287, 0.9571150097465887, 0.9839679358717435)\n",
      "\n",
      "\n",
      "(0.01, 0.9789103690685413, 0.996824480369515, 0.9548133595284872, 0.9739478957915831)\n",
      "\n",
      "\n",
      "(0.02, 0.9830111306385472, 0.9971131639722863, 0.9681274900398407, 0.9739478957915831)\n",
      "\n",
      "\n",
      "(0.04, 0.9794961921499707, 0.995958429561201, 0.9566929133858267, 0.9739478957915831)\n",
      "\n",
      "\n",
      "(0.08, 0.9578207381370826, 0.9740184757505773, 0.9797752808988764, 0.87374749498998)\n",
      "\n",
      "\n",
      "(0.1, 0.9390743995313415, 0.9627598152424942, 0.9759036144578314, 0.811623246492986)\n",
      "\n",
      "\n",
      "(0.2, 0.7076742823667252, 0.7113163972286374, -1, 0.0)\n",
      "\n",
      "\n",
      "(0.4, 0.7076742823667252, 0.7113163972286374, -1, 0.0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training data error calculation\n",
    "metrics = []\n",
    "predictions = []\n",
    "m_train = len(y_train)\n",
    "m_test = len(y_test)\n",
    "tracker = 0\n",
    "\n",
    "for mod in models:\n",
    "    train_prediction = mod.predict(X_train)\n",
    "    current_train_predictions = train_prediction >= 0.5\n",
    "    training_correct = 0\n",
    "    for i in range(m_train):\n",
    "        if current_train_predictions[i] == y_train[i]:\n",
    "           training_correct = training_correct + 1\n",
    "    training_percentage = training_correct/m_train\n",
    "    test_prediction = mod.predict(X_test)\n",
    "    current_test_prediction = test_prediction >= 0.5\n",
    "    testing_correct = 0\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_neg = 0\n",
    "    for i in range(m_test):\n",
    "        if current_test_prediction[i] == y_test[i]:\n",
    "            testing_correct = testing_correct + 1\n",
    "    #else:\n",
    "     #   print(str(prediction[i]) + \" \" + str(current_predictions[i]) + \" \" + str(y_test[i]))\n",
    "        if y_test[i] == 1:\n",
    "            if(current_test_prediction[i] == 1):\n",
    "                true_positive = true_positive + 1\n",
    "            else: \n",
    "                false_neg = false_neg + 1\n",
    "        elif y_test[i] == 0: \n",
    "            if(current_test_prediction[i] == 1):\n",
    "                false_positive = false_positive + 1\n",
    "    testing_percentage = testing_correct/m_test\n",
    "    if true_positive + false_positive == 0:\n",
    "        precision = -1\n",
    "    else:\n",
    "        precision = true_positive/(true_positive + false_positive)\n",
    "    recall = true_positive/(true_positive + false_neg)\n",
    "    metrics.append((lambda_values[tracker],testing_percentage, training_percentage, precision, recall))\n",
    "    predictions.append(train_prediction)\n",
    "    tracker = tracker + 1\n",
    "    \n",
    "\n",
    "for x in metrics:\n",
    "    print(x)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(correct)\n",
    "\n",
    "#for i in range(m):\n",
    "#    print(str(prediction[i]) + \" \" + str(current_predictions[i]) + \" \" + str(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.8953878e-03]\n",
      " [2.1968722e-06]\n",
      " [9.9836594e-01]\n",
      " ...\n",
      " [1.3630579e-03]\n",
      " [1.0798749e-03]\n",
      " [4.6668983e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 5ms/step\n",
      "[0.99827325] [ True] 0\n",
      "[0.8357998] [ True] 0\n",
      "[0.9999998] [ True] 0\n",
      "[0.8446621] [ True] 0\n",
      "[0.99419993] [ True] 0\n",
      "[0.02697792] [False] 1\n",
      "[0.9984414] [ True] 0\n",
      "[0.99901587] [ True] 0\n",
      "[6.213976e-08] [False] 1\n",
      "[0.98169065] [ True] 0\n",
      "[0.13938086] [False] 1\n",
      "[1.9749943e-06] [False] 1\n",
      "[0.51889974] [ True] 0\n",
      "[0.70899504] [ True] 0\n",
      "[0.3506647] [False] 1\n",
      "[0.00074368] [False] 1\n",
      "[0.94985217] [ True] 0\n",
      "[0.00724217] [False] 1\n",
      "[0.8656552] [ True] 0\n",
      "[1.8059904e-32] [False] 1\n",
      "[2.8101109e-05] [False] 1\n",
      "[0.00088663] [False] 1\n",
      "[1.3561309e-08] [False] 1\n",
      "[0.8948978] [ True] 0\n",
      "[0.56893057] [ True] 0\n",
      "[0.82568794] [ True] 0\n",
      "[0.00016525] [False] 1\n",
      "[0.49308693] [False] 1\n",
      "[0.56937325] [ True] 0\n",
      "[0.41436535] [False] 1\n",
      "[1.] [ True] 0\n",
      "[0.7243506] [ True] 0\n",
      "[0.06220069] [False] 1\n",
      "[0.95988274] [ True] 0\n",
      "[0.16102728] [False] 1\n",
      "[0.19289881] [False] 1\n",
      "[0.9999035] [ True] 0\n",
      "[0.05568629] [False] 1\n",
      "[0.01268796] [False] 1\n",
      "[0.06797132] [False] 1\n"
     ]
    }
   ],
   "source": [
    "#Testing data prediction\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "current_predictions = prediction >= 0.5\n",
    "m = len(y_test)\n",
    "correct = 0\n",
    "true_positive = 0\n",
    "false_positive = 0\n",
    "false_neg = 0\n",
    "for i in range(m):\n",
    "    if current_predictions[i] == y_test[i]:\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        print(str(prediction[i]) + \" \" + str(current_predictions[i]) + \" \" + str(y_test[i]))\n",
    "    if y_test[i] == 1:\n",
    "        if(current_predictions[i] == 1):\n",
    "            true_positive = true_positive + 1\n",
    "        else: \n",
    "            false_neg = false_neg + 1\n",
    "    elif y_test[i] == 0: \n",
    "        if(current_predictions[i] == 1):\n",
    "            false_positive = false_positive + 1\n",
    "\n",
    "#print(\"Precision: \" + str(true_positive/(true_positive + false_positive)))\n",
    "#print(\"Recall: \" + str(true_positive/(true_positive + false_neg)))\n",
    "#print(correct/m)\n",
    "#print(m - correct)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fa90f43319a9f62bf08ba0d719fa3f083530ec60f6e7ad73b552f81a13c9139"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
